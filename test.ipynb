{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"saved_model\")\n",
    "\n",
    "# Load base model\n",
    "base_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "base_model = AutoModel.from_pretrained(base_model_name)\n",
    "\n",
    "# Load PEFT model\n",
    "model = PeftModel.from_pretrained(base_model, \"saved_model\")\n",
    "model.eval()\n",
    "\n",
    "def calculate_match_score(resume_text, job_role):\n",
    "    # Tokenize inputs separately\n",
    "    resume_inputs = tokenizer(resume_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    job_inputs = tokenizer(job_role, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Use the base model to get embeddings\n",
    "        resume_outputs = model.base_model(\n",
    "            input_ids=resume_inputs['input_ids'], \n",
    "            attention_mask=resume_inputs['attention_mask']\n",
    "        )\n",
    "        job_outputs = model.base_model(\n",
    "            input_ids=job_inputs['input_ids'], \n",
    "            attention_mask=job_inputs['attention_mask']\n",
    "        )\n",
    "\n",
    "        # Use the pooler output for similarity calculation\n",
    "        resume_embeddings = resume_outputs.pooler_output\n",
    "        job_embeddings = job_outputs.pooler_output\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_score = torch.nn.functional.cosine_similarity(resume_embeddings, job_embeddings)\n",
    "\n",
    "    return float(similarity_score.mean()) * 100  # Convert to percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForSequenceClassification(\n",
      "  (base_model): LoraModel(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 384)\n",
      "        (token_type_embeddings): Embedding(2, 384)\n",
      "        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-5): 6 x BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSdpaSelfAttention(\n",
      "                (query): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=384, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (key): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=384, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (value): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=384, out_features=384, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=384, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=384, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_match_score(resume_text, job_role):\n",
    "    # Tokenize inputs separately\n",
    "    resume_inputs = tokenizer(resume_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    job_inputs = tokenizer(job_role, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get embeddings from pooler_output instead of logits\n",
    "        resume_outputs = model(**resume_inputs).pooler_output\n",
    "        job_outputs = model(**job_inputs).pooler_output\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_score = torch.nn.functional.cosine_similarity(resume_outputs, job_outputs)\n",
    "\n",
    "    return float(similarity_score.mean()) * 100  # Convert to percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Score: 86.71%\n"
     ]
    }
   ],
   "source": [
    "resume_sample = \"Software engineer with 5 years of experience in Python and ML.\"\n",
    "job_role_sample = \"Looking for a Python machine learning engineer.\"\n",
    "\n",
    "score = calculate_match_score(resume_sample, job_role_sample)\n",
    "print(f\"Match Score: {score:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
